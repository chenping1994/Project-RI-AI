{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import optuna\n",
    "import keras.backend as Ks\n",
    "import keras\n",
    "from keras.models import load_model \n",
    "from keras.models import Sequential, Model\n",
    "from keras import layers \n",
    "from keras import Input\n",
    "from keras import regularizers\n",
    "from keras.utils import np_utils\n",
    "import pickle, glob, os\n",
    "import random, secrets, glob, csv, pandas\n",
    "import scipy.signal\n",
    "import tensorflow as tf\n",
    "\n",
    "from secrets import randbelow as rb\n",
    "from scipy.optimize import curve_fit as cf\n",
    "from numpy import load, asarray, savez_compressed, save, savetxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## file processing from Kim\n",
    "\n",
    "dir = \"pythonread/\"\n",
    "path_list = glob.glob(dir + '/*.txt')     # 指定されたディレクトリ内の全てのcsvファイルをリストとして取得\n",
    "buf = []\n",
    "# ファイルを順に開き、timeとcountを取得し、DataFrame(df0)に追加\n",
    "\n",
    "filename = os.listdir(dir)\n",
    "\n",
    "# The sequence is as below !!!\n",
    "\n",
    "Co = np.loadtxt(dir+\"Co-Efit.txt\")\n",
    "Cs = np.loadtxt(dir+\"Cs-Efit.txt\")\n",
    "Na = np.loadtxt(dir+\"Na-Efit.txt\")\n",
    "Ba = np.loadtxt(dir+\"Ba-Efit.txt\")\n",
    "Eu = np.loadtxt(dir+\"Eu-Efit.txt\")\n",
    "U235=np.loadtxt(dir+\"U235-Efit.txt\")\n",
    "U238=np.loadtxt(dir+\"U238-Efit.txt\")\n",
    "Th = np.loadtxt(dir+\"Th-Efit.txt\")\n",
    "Ra = np.loadtxt(dir+\"Ra-Efit.txt\")\n",
    "K  = np.loadtxt(dir+\"K-Efit.txt\")\n",
    "\n",
    "nuclides = [Co, Cs, Na, Ba, Eu, U235, U238, Th, Ra, K]\n",
    "nuclides_n = len(nuclides)\n",
    "print(\"Number of nuclides = \",nuclides_n)\n",
    "\n",
    "rng = secrets.SystemRandom()\n",
    "\n",
    "Co = Co.T\n",
    "Cs = Cs.T\n",
    "Na = Na.T\n",
    "Ba = Ba.T\n",
    "Eu = Eu.T\n",
    "U235=U235.T\n",
    "U238=U238.T\n",
    "Th = Th.T\n",
    "Ra = Ra.T\n",
    "K  = K.T\n",
    "\n",
    "# print(Co[1,:])\n",
    "\n",
    "TotBq = []\n",
    "Co_Bq = []\n",
    "Cs_Bq = []\n",
    "Na_Bq = []\n",
    "Ba_Bq = []\n",
    "Eu_Bq = []\n",
    "U235_Bq=[]\n",
    "U238_Bq=[]\n",
    "Th_Bq = []\n",
    "Ra_Bq = []\n",
    "K_Bq  = []\n",
    "\n",
    "Sumpeak = []\n",
    "randEshift=[]\n",
    "PeakNoU235 = []\n",
    "\n",
    "CoCCR = []\n",
    "CsCCR = []\n",
    "NaCCR = []\n",
    "BaCCR = []\n",
    "EuCCR = []\n",
    "U235CCR=[]\n",
    "U238CCR=[]\n",
    "ThCCR = []\n",
    "RaCCR = []\n",
    "KCCR  = []\n",
    "\n",
    "Coccr = []\n",
    "Csccr = []\n",
    "Naccr = []\n",
    "Baccr = []\n",
    "Euccr = []\n",
    "U238ccr=[]\n",
    "Thccr = []\n",
    "Raccr = []\n",
    "Kccr  = []\n",
    "\n",
    "pattern = 2048\n",
    "bit1 = 100\n",
    "bit2 = 1000\n",
    "bit3 = 10000\n",
    "bit4 = 100000\n",
    "bit5 = 1000000\n",
    "bit6 = 10000000\n",
    "\n",
    "bits = [bit1*5, bit2, bit3, bit4, bit5, bit6, bit6*5]\n",
    "\n",
    "Eshiftpatterns = [i for i in range(100)]\n",
    "\n",
    "Datasize = 479    # 483 = 1.507 MeV # 479 = 1.5006 MeV (poly equation for detector) ; 1.494 MeV (linear eq for simulation)\n",
    "Startsize = 19    # Minus front 60 keV (cutoff in experimental data too )\n",
    "Measurement_time = 60.0  # in seconds\n",
    "\n",
    "print(Co.shape)\n",
    "# Co2 = np.roll(Co, -5, axis=1)\n",
    "# print(Co2)\n",
    "# allres = np.vstack((Co, Cs))\n",
    "# plt.plot(np.arange(1024),allres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Co = np.loadtxt(dir+\"resCo.txt\")\n",
    "Cs = np.loadtxt(dir+\"resCs.txt\")\n",
    "Na = np.loadtxt(dir+\"resNa.txt\")\n",
    "Ba = np.loadtxt(dir+\"resBa.txt\")\n",
    "Eu = np.loadtxt(dir+\"resEu.txt\")\n",
    "\n",
    "U235=np.loadtxt(dir+\"resU235.txt\")\n",
    "U238=np.loadtxt(dir+\"resU238.txt\")\n",
    "Th = np.loadtxt(dir+\"resTh.txt\")\n",
    "Ra = np.loadtxt(dir+\"resRa.txt\")\n",
    "K  = np.loadtxt(dir+\"resK.txt\")\n",
    "\n",
    "\n",
    "###############################################\n",
    "## Compton edge fitting\n",
    "## Cs-137\n",
    "###############################################\n",
    "plt.plot(Cs)\n",
    "ch = np.arange(1024)\n",
    "\n",
    "X = ch[15:54]\n",
    "m = -0.00483226978228295\n",
    "c = 0.463047994313389\n",
    "funcLinear = m*X + c\n",
    "\n",
    "X = ch[54:67]\n",
    "A = 0.07\n",
    "B = 65.0764\n",
    "Sigma = 1.58\n",
    "m1= -0.00199462114328639\n",
    "c1= 0.31\n",
    "funcGauss = A*np.exp((-(X-B)**2)/(2*Sigma**2)) + m1*X + c1\n",
    "\n",
    "X = ch[67:146]\n",
    "p1= 2.75786455226826e-05\n",
    "q1= -0.0075301414126459\n",
    "r1= 0.583456592607807\n",
    "funcPoly1 = p1*X*X + q1*X + r1\n",
    "\n",
    "X = ch[146:203]\n",
    "p2= 4.41035e-05\n",
    "q2= -0.0162693\n",
    "r2= 1.50802\n",
    "funcPoly2 = p2*X*X + q2*X + r2\n",
    "\n",
    "Cs[15:54] = funcLinear/700\n",
    "Cs[54:67] = funcGauss/700\n",
    "Cs[67:146]= funcPoly1/700\n",
    "Cs[146:203]=funcPoly2/700\n",
    "\n",
    "np.savetxt(dir+'Cs-ComptonEdgefit.txt', Cs)\n",
    "\n",
    "plt.plot(Cs)\n",
    "plt.show()\n",
    "\n",
    "###############################################\n",
    "## Ba-133\n",
    "###############################################\n",
    "\n",
    "BaExp = np.loadtxt(dir+\"Ba133_data_sum.csv_rem_BG.csv\", delimiter=',')\n",
    "plt.yscale(\"log\")\n",
    "plt.ylim((1e-2, 1000))\n",
    "plt.plot(BaExp[:200])\n",
    "\n",
    "X = ch[33:50]\n",
    "#ComptonDiffBa = -3.4267e-7 * X * X + 0.000036723 * X - 0.000619777\n",
    "#ComptonDiffBa = -1.8915e-7 * X * X + 0.0000197422 * X - 0.000176637\n",
    "#ComptonDiffBa = -3.95765e-6 * X + 0.000508432\n",
    "ComptonDiffBa = 1.36364e-6 * X * X - 0.000107364 * X + 0.00236582\n",
    "Ba[33:50] += ComptonDiffBa\n",
    "\n",
    "X = ch[50:86]\n",
    "ComptonDiffBa2 = 3.7567e-7 * X * X - 0.0000617811 * X + 0.00267497\n",
    "Ba[50:86] += ComptonDiffBa2\n",
    "\n",
    "X = ch[86:93]\n",
    "ComptonDiffBa3 = -7.0226e-7 * X * X + 0.000137086 * X - 0.00639702\n",
    "Ba[86:93] = ComptonDiffBa3\n",
    "\n",
    "X = ch[46:54]\n",
    "A = 17.5\n",
    "B = 53.55\n",
    "Sigma = 6.2148\n",
    "m1= -0.0756563770302553\n",
    "c1= 15.1512660503501\n",
    "funcGauss1 = A*np.exp((-(X-B)**2)/(2*Sigma**2)) + m1*X + c1\n",
    "Ba[46:54] = funcGauss1/50000\n",
    "\n",
    "np.savetxt(dir+'Ba-ComptonEdgefit.txt', Ba)\n",
    "\n",
    "plt.plot(Ba[:200]*50000)\n",
    "plt.show()\n",
    "\n",
    "###############################################\n",
    "## Co-60\n",
    "###############################################\n",
    "X = ch[9:82]\n",
    "A = 0.3\n",
    "B = 26.55\n",
    "Sigma = 1.28622260795426\n",
    "d  = 0.86\n",
    "A1 = 0.59\n",
    "B1 = 76.9796547661445\n",
    "Sigma1 = 5.22865794880\n",
    "funcGauss2 = A*np.exp((-(X-B)**2)/(2*Sigma**2)) + A1*np.exp((-(X-B1)**2)/(2*Sigma1**2)) + d\n",
    "Co[9:82] = funcGauss2/5000\n",
    "\n",
    "X = ch[82:137]\n",
    "Poly1 = 0.000188314908045988 * X * X - 0.0549161877815528 * X + 4.50061786812904\n",
    "Co[82:137] = Poly1/5000\n",
    "\n",
    "X = ch[137:292]\n",
    "Poly2 = 1.50499926937746e-05 * X * X - 0.00595277558578775 * X + 1.0329505637320\n",
    "Co[137:292] = Poly2/5000\n",
    "\n",
    "X = ch[292:359]\n",
    "A = 0.065\n",
    "B = 340\n",
    "Sigma = 7\n",
    "dd = -0.00130483903987569\n",
    "ee = 0.711819904747457\n",
    "A1 = 0.256\n",
    "B1 = 296\n",
    "Sigma1 = 15\n",
    "funcGauss3 = A*np.exp((-(X-B)**2)/(2*Sigma**2)) + A1*np.exp((-(X-B1)**2)/(2*Sigma1**2)) + dd * X + ee\n",
    "Co[292:359] = funcGauss3/5000\n",
    "\n",
    "X = ch[384:420]\n",
    "pp =  0.0016624285157812\n",
    "qq = -1.34253956318541\n",
    "rr = 271.185755248658\n",
    "Poly3 = pp * X * X + qq * X + rr\n",
    "Co[384:420] = Poly3/5000\n",
    "\n",
    "np.savetxt(dir+'Co-ComptonEdgefit.txt', Co)\n",
    "\n",
    "plt.plot(Co)\n",
    "plt.show()\n",
    "\n",
    "###############################################\n",
    "## Na-22\n",
    "###############################################\n",
    "\n",
    "NaExp = np.loadtxt(dir+\"Na22_data_sum.csv_rem_BG.csv\", delimiter=',')\n",
    "plt.yscale(\"log\")\n",
    "plt.ylim((1e-2, 100))\n",
    "plt.plot(NaExp[:Datasize])\n",
    "\n",
    "X = ch[9:69]\n",
    "A = 1.26\n",
    "B = 63.8203599955983\n",
    "Sigma = 6\n",
    "d  = 1.56\n",
    "A1 = 0.571168936575289\n",
    "B1 = 26.5813369461101\n",
    "Sigma1 = 1.33444417051575\n",
    "funcGauss3 = A*np.exp((-(X-B)**2)/(2*Sigma**2)) + A1*np.exp((-(X-B1)**2)/(2*Sigma1**2)) + d\n",
    "Na[9:69] = funcGauss3 / 4200\n",
    "\n",
    "X = ch[69:105]\n",
    "Poly1 = 0.000418911418990103 * X * X - 0.106367639044028 * X + 7.6510123507193\n",
    "Na[69:105] = Poly1/4200\n",
    "\n",
    "X = ch[105:118]\n",
    "Poly2 = 0.00135027597720696 * X * X - 0.34754137775294 * X + 22.7567960331933\n",
    "Na[105:118] = Poly2/4200\n",
    "\n",
    "X = ch[118:155]\n",
    "Poly3 = 0.000412795336697596 * X * X - 0.116382701296672 * X + 8.53211650098415\n",
    "Na[118:155] = Poly3/4200\n",
    "\n",
    "np.savetxt(dir+'Na-ComptonEdgefit.txt', Na)\n",
    "\n",
    "plt.plot(Na[:Datasize]*4000)\n",
    "plt.show()\n",
    "\n",
    "###############################################\n",
    "## Eu-152\n",
    "###############################################\n",
    "plt.yscale(\"log\")\n",
    "plt.ylim((1e-7, 10))\n",
    "plt.xlim((0, Datasize))\n",
    "plt.plot(Eu)\n",
    "\n",
    "X = ch[19:33]\n",
    "ComptonDiffEu = 0.0000634888 * X - 0.00132484\n",
    "Eu[19:33] += ComptonDiffEu\n",
    "\n",
    "X = ch[33:39]\n",
    "ComptonDiffEu = 2.46/7000  \n",
    "Eu[33:39] += ComptonDiffEu\n",
    "\n",
    "X = ch[47:82]\n",
    "ComptonDiffEu = -0.00000568367 * X + 0.000551143\n",
    "Eu[47:82] += ComptonDiffEu\n",
    "\n",
    "X = ch[82:84]\n",
    "ComptonDiffEu = 0.58873/7000\n",
    "Eu[82:84] += ComptonDiffEu\n",
    "\n",
    "X = ch[84:110]\n",
    "ComptonDiffEu = 0.00000156 * X - 0.0000803657\n",
    "Eu[84:110] += ComptonDiffEu\n",
    "\n",
    "X = ch[110:111]\n",
    "ComptonDiffEu = 0.25/7000  \n",
    "Eu[110:111] += ComptonDiffEu\n",
    "\n",
    "X = ch[111:112]\n",
    "ComptonDiffEu = 0.2/7000  \n",
    "Eu[111:112] += ComptonDiffEu\n",
    "\n",
    "X = ch[126:148]\n",
    "ComptonDiffEu = 0.14/7000  \n",
    "Eu[126:148] += ComptonDiffEu\n",
    "\n",
    "X = ch[148:149]\n",
    "ComptonDiffEu = 0.13/7000  \n",
    "Eu[148:149] += ComptonDiffEu\n",
    "\n",
    "X = ch[149:179]\n",
    "ComptonDiffEu = 0.12/7000  \n",
    "Eu[149:179] += ComptonDiffEu\n",
    "\n",
    "X = ch[179:192]\n",
    "ComptonDiffEu = 0.10/7000  \n",
    "Eu[179:192] += ComptonDiffEu\n",
    "\n",
    "X = ch[192:193]\n",
    "ComptonDiffEu = 0.09/7000  \n",
    "Eu[192:193] += ComptonDiffEu\n",
    "\n",
    "X = ch[193:230]\n",
    "ComptonDiffEu = 0.08/7000  \n",
    "Eu[193:230] += ComptonDiffEu\n",
    "\n",
    "X = ch[230:238]\n",
    "ComptonDiffEu = 0.065/7000  \n",
    "Eu[230:238] += ComptonDiffEu\n",
    "\n",
    "X = ch[238:279]\n",
    "ComptonDiffEu = 0.05/7000  \n",
    "Eu[238:279] += ComptonDiffEu\n",
    "\n",
    "X = ch[279:281]\n",
    "ComptonDiffEu = 0.04/7000  \n",
    "Eu[279:281] += ComptonDiffEu\n",
    "\n",
    "X = ch[281:376]\n",
    "ComptonDiffEu = 0.025/7000  \n",
    "Eu[281:376] += ComptonDiffEu\n",
    "\n",
    "X = ch[376:434]\n",
    "ComptonDiffEu = 0.01/7000  \n",
    "Eu[376:434] += ComptonDiffEu\n",
    "\n",
    "X = ch[434:437]\n",
    "ComptonDiffEu = 0.005/7000  \n",
    "Eu[434:437] += ComptonDiffEu\n",
    "\n",
    "X = ch[437:442]\n",
    "ComptonDiffEu = 0.0025/7000  \n",
    "Eu[437:442] += ComptonDiffEu\n",
    "\n",
    "np.savetxt(dir+'Eu-ComptonEdgefit.txt', Eu)\n",
    "plt.plot(Eu)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ==============================================##\n",
    "###################################################\n",
    "## Simulation\n",
    "###################################################\n",
    "\n",
    "Measurement_time = 60 ### 60 sec for sim  data\n",
    "\n",
    "for Eshift in Eshiftpatterns:  \n",
    "   \n",
    "    s1 = secrets.choice(range(-3,4))     # rolling about \n",
    "    randEshift.append(s1)\n",
    "    \n",
    "    tempCo = np.roll(Co, -s1)\n",
    "    tempCs = np.roll(Cs, -s1)\n",
    "    tempNa = np.roll(Na, -s1)    \n",
    "    tempBa = np.roll(Ba, -s1)    \n",
    "    tempEu = np.roll(Eu, -s1)\n",
    "    tempU235=np.roll(U235, -s1)\n",
    "    tempU238=np.roll(U238, -s1)\n",
    "    tempTh = np.roll(Th, -s1)\n",
    "    tempRa = np.roll(Ra, -s1)\n",
    "    tempK  = np.roll(K, -s1)\n",
    "    \n",
    "    for bit in bits:\n",
    "        for i in range(pattern):\n",
    "            \n",
    "            x1 = rng.uniform((bit/10), (bit))\n",
    "            x2 = rng.uniform((bit/10), (bit))\n",
    "            x3 = rng.uniform((bit/10), (bit))\n",
    "            x4 = rng.uniform((bit/10), (bit))\n",
    "            x5 = rng.uniform((bit/10), (bit))\n",
    "            x6 = rng.uniform((bit/10), (bit))\n",
    "            x7 = rng.uniform((bit/10), (bit))\n",
    "            x8 = rng.uniform((bit/10), (bit))\n",
    "            x9 = rng.uniform((bit/10), (bit))\n",
    "            x10 = rng.uniform((bit/10), (bit))\n",
    "            \n",
    "            xsum = x1+x2+x3+x4+x5+x6+x7+x8+x9+x10\n",
    "            \n",
    "            #xtot = bit\n",
    "            xtot = rng.uniform((bit/10), (bit))\n",
    "            x1 = x1/xsum * xtot\n",
    "            x2 = x2/xsum * xtot\n",
    "            x3 = x3/xsum * xtot\n",
    "            x4 = x4/xsum * xtot\n",
    "            x5 = x5/xsum * xtot\n",
    "            x6 = x6/xsum * xtot\n",
    "            x7 = x7/xsum * xtot\n",
    "            x8 = x8/xsum * xtot\n",
    "            x9 = x9/xsum * xtot\n",
    "            x10 = x10/xsum * xtot\n",
    "\n",
    "            Co_Bq.append(x1)\n",
    "            Cs_Bq.append(x2)\n",
    "            Na_Bq.append(x3)            \n",
    "            Ba_Bq.append(x4)            \n",
    "            Eu_Bq.append(x5)\n",
    "            U235_Bq.append(x6)\n",
    "            U238_Bq.append(x7)\n",
    "            Th_Bq.append(x8)\n",
    "            Ra_Bq.append(x9)\n",
    "            K_Bq.append(x10)\n",
    "            TotBq.append(xtot)\n",
    "\n",
    "            co60 = np.round(Measurement_time *x1*tempCo[Startsize:Datasize])  \n",
    "            cs137 = np.round(Measurement_time*x2*tempCs[Startsize:Datasize])\n",
    "            na22 = np.round(Measurement_time *x3*tempNa[Startsize:Datasize])            \n",
    "            ba133 = np.round(Measurement_time*x4*tempBa[Startsize:Datasize])\n",
    "            eu152 = np.round(Measurement_time*x5*tempEu[Startsize:Datasize])\n",
    "            u235 = np.round(Measurement_time *x6*tempU235[Startsize:Datasize])\n",
    "            u238 = np.round(Measurement_time *x7*tempU238[Startsize:Datasize])\n",
    "            th232 = np.round(Measurement_time*x8*tempTh[Startsize:Datasize])\n",
    "            ra226 = np.round(Measurement_time*x9*tempRa[Startsize:Datasize])\n",
    "            k40 = np.round(Measurement_time  *x10*tempK[Startsize:Datasize])\n",
    "\n",
    "            ww = co60 + cs137 + na22  + ba133  + eu152 + u235 + u238 + th232 + ra226 + k40\n",
    "            uu = ww - u235\n",
    "            \n",
    "            Sumpeak.append(ww)\n",
    "            PeakNoU235.append(uu)\n",
    "            \n",
    "            sumww = np.sum(ww,axis=0)\n",
    "            sumuu = np.sum(uu,axis=0)\n",
    "            \n",
    "            CoCCR.append(np.sum(co60,axis=0)/sumww)\n",
    "            CsCCR.append(np.sum(cs137,axis=0)/sumww)\n",
    "            NaCCR.append(np.sum(na22,axis=0)/sumww)            \n",
    "            BaCCR.append(np.sum(ba133,axis=0)/sumww)\n",
    "            EuCCR.append(np.sum(eu152,axis=0)/sumww)\n",
    "            U235CCR.append(np.sum(u235,axis=0)/sumww)\n",
    "            U238CCR.append(np.sum(u238,axis=0)/sumww)\n",
    "            ThCCR.append(np.sum(th232,axis=0)/sumww)\n",
    "            RaCCR.append(np.sum(ra226,axis=0)/sumww)\n",
    "            KCCR.append(np.sum(k40,axis=0)/sumww)\n",
    "            \n",
    "            \n",
    "            Coccr.append(np.sum(co60,axis=0)/sumuu)\n",
    "            Csccr.append(np.sum(cs137,axis=0)/sumuu)\n",
    "            Naccr.append(np.sum(na22,axis=0)/sumuu)            \n",
    "            Baccr.append(np.sum(ba133,axis=0)/sumuu)\n",
    "            Euccr.append(np.sum(eu152,axis=0)/sumuu)\n",
    "            U238ccr.append(np.sum(u238,axis=0)/sumuu)\n",
    "            Thccr.append(np.sum(th232,axis=0)/sumuu)\n",
    "            Raccr.append(np.sum(ra226,axis=0)/sumuu)\n",
    "            Kccr.append(np.sum(k40,axis=0)/sumuu)\n",
    "            \n",
    "# Sum = np.vstack((Co[0,0:Datasize], Sumpeak))\n",
    "Sum = np.vstack((Co[Startsize:Datasize], Sumpeak))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Sumpeak[0])\n",
    "plt.show()\n",
    "plt.plot(BaCCR[:100000])\n",
    "#plt.plot(NaCCR[:100000])\n",
    "plt.plot(CsCCR[:100000])\n",
    "plt.show()\n",
    "plt.plot(CoCCR[:10000])\n",
    "plt.show()\n",
    "bg4ccr = ThCCR + RaCCR + KCCR + U238CCR\n",
    "plt.plot(bg4ccr[:20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclides_n = 10\n",
    "\n",
    "X_train = np.array(Sumpeak)\n",
    "\n",
    "CCR = np.vstack([CoCCR, CsCCR, NaCCR,  BaCCR, EuCCR, U235CCR, U238CCR, ThCCR, RaCCR, KCCR])\n",
    "\n",
    "ccr_no_U235 = np.vstack([Coccr, Csccr, Naccr,  Baccr, Euccr, U238ccr, Thccr, Raccr, Kccr])\n",
    "\n",
    "Activity = np.vstack([TotBq, Co_Bq, Cs_Bq, Na_Bq,  Ba_Bq, Eu_Bq, U235_Bq, U238_Bq, Th_Bq, Ra_Bq, K_Bq])\n",
    "\n",
    "Y_train = CCR.T\n",
    "\n",
    "print(X_train.shape)\n",
    "print(np.shape(Y_train))\n",
    "\n",
    "np.savetxt(\"YtrainCCR_Sim.txt\", CCR.T)\n",
    "np.savetxt(\"X_train_Sim.npy\", X_train)\n",
    "np.savetxt(\"Y_train_Sim.npy\", Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BgCCR = np.stack(U238CCR) + np.stack(KCCR) + np.stack(ThCCR) + np.stack(RaCCR)\n",
    "print(BgCCR.shape)\n",
    "\n",
    "CCR_acc_no_U235 = np.vstack([Coccr, Csccr, Naccr,  Baccr, Euccr, BgCCR])\n",
    "CCR_acc = np.vstack([CoCCR, CsCCR, NaCCR,  BaCCR, EuCCR, U235CCR, BgCCR])\n",
    "\n",
    "Y_train_acc = CCR_acc.T\n",
    "Y_train_acc_no_U235 = CCR_acc_no_U235.T\n",
    "\n",
    "np.savetxt(\"YtrainCCR_acc_Sim.txt\", CCR_acc.T)\n",
    "np.savetxt(\"YtrainCCR_acc_no_U235_Sim.txt\", CCR_acc_no_U235.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nuclides_n = 7\n",
    "X_train = np.load('X_train_Sim.npy')\n",
    "Y_train = np.load('Y_train_Sim.npy')\n",
    "print(X_train.shape, np.shape(Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG19 model定義\n",
    "Ks.clear_session()\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "VGG19model = keras.models.Sequential()\n",
    "\n",
    "VGG19model.add(layers.Conv1D(64, 3, activation = 'relu', padding='same',\n",
    "                       input_shape = (Datasize-Startsize,1)))\n",
    "VGG19model.add(layers.Conv1D(64, 3, padding='same', activation = 'relu'))\n",
    "VGG19model.add(layers.MaxPooling1D(2))\n",
    "\n",
    "VGG19model.add(layers.Conv1D(128, 3, padding='same', activation = 'relu'))\n",
    "VGG19model.add(layers.Conv1D(128, 3, padding='same', activation = 'relu'))\n",
    "VGG19model.add(layers.MaxPooling1D(2))\n",
    "\n",
    "VGG19model.add(layers.Conv1D(256, 3, padding='same', activation = 'relu'))\n",
    "VGG19model.add(layers.Conv1D(256, 3, padding='same', activation = 'relu'))\n",
    "VGG19model.add(layers.Conv1D(256, 3, padding='same', activation = 'relu'))\n",
    "VGG19model.add(layers.Conv1D(256, 3, padding='same', activation = 'relu'))\n",
    "VGG19model.add(layers.MaxPooling1D(2))\n",
    "VGG19model.add(layers.Conv1D(512, 3, padding='same', activation = 'relu'))\n",
    "VGG19model.add(layers.Conv1D(512, 3, padding='same', activation = 'relu'))\n",
    "VGG19model.add(layers.Conv1D(512, 3, padding='same', activation = 'relu'))\n",
    "VGG19model.add(layers.Conv1D(512, 3, padding='same', activation = 'relu'))\n",
    "VGG19model.add(layers.MaxPooling1D(2))\n",
    "VGG19model.add(layers.Conv1D(512, 3, padding='same', activation = 'relu'))\n",
    "VGG19model.add(layers.Conv1D(512, 3, padding='same', activation = 'relu'))\n",
    "VGG19model.add(layers.Conv1D(512, 3, padding='same', activation = 'relu'))\n",
    "VGG19model.add(layers.Conv1D(512, 3, padding='same', activation = 'relu'))\n",
    "VGG19model.add(layers.MaxPooling1D(2))\n",
    "VGG19model.add(layers.Flatten())\n",
    "#model.add(layers.Dense(64, activation='relu'))\n",
    "VGG19model.add(layers.Dense(1024, activation='relu'))\n",
    "VGG19model.add(layers.Dense(1024, activation='relu'))\n",
    "VGG19model.add(layers.Dropout(0.2))\n",
    "VGG19model.add(layers.Dense(nuclides_n, activation='softmax'))\n",
    "\n",
    "#opt= keras.optimizers.Adam(lr=0.0021533133440412807,\n",
    "#                           decay=8.915893662822524e-09,\n",
    "#                           amsgrad=True)\n",
    "opt = keras.optimizers.Adam()\n",
    "\n",
    "VGG19model.compile(loss='categorical_crossentropy', optimizer=opt, metrics = ['accuracy'])\n",
    "\n",
    "VGG19model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "data_x = X_train.reshape(X_train.shape[0], X_train.shape[1], 1) # 学習データをConv1D Layer用に変形\n",
    "print(data_x.shape)\n",
    "\n",
    "data_y = Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG19 学習\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "run = 15\n",
    "val_split = 0.2\n",
    "batch_size = 1024\n",
    "\n",
    "VGGhistory = VGG19model.fit(data_x, data_y, \n",
    "                    epochs=run,\n",
    "                            \n",
    "                    batch_size=batch_size,\n",
    "                    validation_split=val_split)\n",
    "#                    callbacks=EarlyStopping(monitor='val_loss',patience=50, verbose=1, min_delta=0,mode=\"auto\"))\n",
    "\n",
    "VGGloss = VGGhistory.history['loss']\n",
    "VGGval_loss = VGGhistory.history['val_loss']\n",
    "\n",
    "#epochs= range(len(acc))\n",
    "epochs= range(len(VGGloss))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, VGGloss, 'bo', label='training loss')\n",
    "plt.plot(epochs, VGGval_loss, 'b', label='validation loss')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"loss-5epochs-7bits-Compton-Eu-fitted\")\n",
    "VGG19model.save(dir+\"/VGG19-1D_5epoch-dropout0.2-7bits-Compton.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG19model = keras.models.load_model(\"./VGG19-1D_5epoch-dropout0.2-7bits-Compton.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path0 = 'RItest/'\n",
    "dirs = os.listdir(path0)\n",
    "direc = dirs\n",
    "\n",
    "obj_list = glob.glob(path0 + '/*.csv')\n",
    "temp = [] \n",
    "Sum = []\n",
    "ccr = []\n",
    "x_test = []\n",
    "filen = []\n",
    "measure_t = 60 * 30\n",
    "\n",
    "BG = np.sum(np.loadtxt(path0 + 'BG_sum_.csv'))/(60*900)\n",
    "Cf = np.sum(np.loadtxt(path0 + 'Cf_sum_.csv'))/(60*2268)\n",
    "\n",
    "for filename in obj_list:\n",
    "    temp.append(np.loadtxt(filename, delimiter = ','))\n",
    "    x_test.append(np.loadtxt(filename, delimiter = ','))\n",
    "    a = np.stack(temp, axis = 0)\n",
    "    Sum.append(np.sum(a))\n",
    "    cps = np.sum(a)/measure_t\n",
    "    ccr.append(cps/(BG + cps))\n",
    "    temp = [] \n",
    "\n",
    "## correction of order from file naming order to CCR aranging order\n",
    "x_test = np.stack(x_test, axis = 0)\n",
    "\n",
    "direct = ['Co','Cs','Na','Ba','Eu','BG','CoCs', 'CoNa', 'CoBa', 'CoEu', 'CsNa', 'CsBa',\n",
    "    'CsEu', 'BaNa','NaEu','BaEu','CoCsNa', 'CoCsBa', 'CoCsEu', 'CoBaNa', 'CoNaEu', 'CoBaEu', \n",
    "           'CsBaNa', 'CsNaEu','CsBaEu', 'BaNaEu', 'CoCsBaNa', 'CoCsNaEu', 'CoCsBaEu', 'CoBaNaEu', 'CsBaNaEu'] \n",
    "\n",
    "\n",
    "for j in range(len(direct)):\n",
    "    x_test[j] = np.loadtxt(path0 + direct[j] + '_sum_.csv', delimiter = ',')\n",
    "    if direct[j] == BG:\n",
    "        x_test[j] = x_test[j]/(60*900)\n",
    "    \n",
    "print(x_test[11, 20:])\n",
    "print(x_test[12, 20:])\n",
    "print(x_test[13, 20:])\n",
    "\n",
    "x_test = np.delete(x_test, len(x_test)-1,axis=0)\n",
    "\n",
    "x_test = x_test[:, Startsize:Datasize]\n",
    "\n",
    "\"\"\"\n",
    "no\tCo\tCs\tNa\tBa\tEu\tBg\n",
    "0\t1\t\t\t\t\t1\n",
    "16\t\t1\t\t\t\t1\n",
    "20\t\t\t1\t\t\t1\n",
    "21\t\t\t\t1\t\t1\n",
    "22\t\t\t\t\t1\t1\n",
    "26\t\t\t\t\t\t1\n",
    "14\t1\t1\t\t\t\t1\n",
    "23\t1\t\t1\t\t\t1\n",
    "18\t1\t\t\t1\t\t1\n",
    "28\t1\t\t\t\t1\t1\n",
    "19\t\t1\t1\t\t\t1\n",
    "29\t\t1\t\t1\t\t1\n",
    "5\t\t1\t\t\t1\t1\n",
    "7\t\t\t1\t1\t\t1\n",
    "6\t\t\t1\t\t1\t1\n",
    "8\t\t\t\t1\t1\t1\n",
    "30\t1\t1\t1\t\t\t1\n",
    "2\t1\t1\t\t1\t\t1\n",
    "12\t1\t1\t\t\t1\t1\n",
    "27\t1\t\t1\t1\t\t1\n",
    "3\t1\t\t1\t\t1\t1\n",
    "11\t1\t\t\t1\t1\t1\n",
    "13\t\t1\t1\t1\t\t1\n",
    "17\t\t1\t1\t\t1\t1\n",
    "24\t\t1\t\t1\t1\t1\n",
    "15\t\t\t1\t1\t1\t1\n",
    "10\t1\t1\t1\t1\t\t1\n",
    "4\t1\t1\t1\t\t1\t1\n",
    "31\t1\t1\t\t1\t1\t1\n",
    "9\t1\t\t1\t1\t1\t1\n",
    "25\t\t1\t1\t1\t1\t1\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#correction for Cs and BG\n",
    "ccr[1] = Cf / (Cf + BG)\n",
    "ccr[27-1] = BG / (BG)\n",
    "\n",
    "print(ccr[31])\n",
    "\n",
    "## convert data to cps\n",
    "# x_test = x_test / measure_t\n",
    "\n",
    "\n",
    "print(x_test.shape)\n",
    "print(x_test[11, 20:50])\n",
    "\n",
    "np.savetxt('x_test.txt', x_test)\n",
    "\n",
    "X_test = np.loadtxt('x_test.txt')\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], 1)\n",
    "print(x_test.shape)\n",
    "\n",
    "y_test = np.loadtxt(\"y_test.txt\", encoding = 'utf-8')\n",
    "print(x_test.shape, y_test.shape)\n",
    "print(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_test = np.loadtxt(\"x_test_1min.txt\") ### 1min, 3min, 5min, 10min, 20min; for 30min: x_test.txt \n",
    "\n",
    "result_y = VGG19model.predict(x_test)\n",
    "print(result_y.shape)\n",
    "print(result_y[0,:])\n",
    "\n",
    "\n",
    "BG = result_y[:, 6]+ result_y[:, 7] + result_y[:, 8] + result_y[:, 9] #  238, Th, Ra, K\n",
    "BG = BG.reshape(BG.shape[0], 1)\n",
    "\n",
    "res_y = np.hstack((result_y[:, :5], BG))\n",
    "print(BG.shape)\n",
    "print(res_y.shape)\n",
    "\n",
    "names = np.array([\"Co60\", \"Cs137\", \"Na22\", \"Ba133\", \"Eu152\", \"BG\"])\n",
    "\n",
    "\n",
    "left = np.arange(res_y.shape[1])\n",
    "width = 0.4\n",
    "\n",
    "for i in range(res_y.shape[0]):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    plt.bar(left, res_y[i], width=width, align='center')\n",
    "    plt.bar(left+width, y_test[i], width=width, align='center')\n",
    "    plt.xticks(left + width/2, names)\n",
    "    plt.savefig(\"June30-100epoch-7bits-Compton-cut60keV-{:03}.png\".format(i))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "np.savetxt(\"result_y.csv\",result_y,delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "RI = res_y.T\n",
    "RI_exp = y_test.T\n",
    "TP = []\n",
    "FN = []\n",
    "FP = []\n",
    "\n",
    "for i in range(len(RI)-1):\n",
    "    RI_detected = np.where(RI[i,:]>RI[5,:], 1, 0)\n",
    "    RI_EXP = np.where(RI_exp[i,:]>RI_exp[5,:], 1, 0)\n",
    "    RI_EXP_TP = np.where(RI_EXP == 1, 1, -1)\n",
    "    RI_TP = np.where(RI_detected == RI_EXP_TP, 1, 0)\n",
    "    TP.append(np.sum(RI_TP))\n",
    "    FN.append(np.sum(np.where(RI_EXP>RI_detected, 1,0)))\n",
    "    FP.append(np.sum(np.where(RI_detected>RI_EXP, 1,0)))\n",
    "\n",
    "Tp = np.sum(np.stack(TP))\n",
    "Fn = np.sum(np.stack(FN))\n",
    "Fp = np.sum(np.stack(FP))\n",
    "\n",
    "print(Tp, Fn, Fp)\n",
    "\n",
    "precision = Tp/(Tp+Fp)\n",
    "recall = Tp/(Tp+Fn)\n",
    "F_score = 100*2*precision*recall/(precision + recall)\n",
    "\n",
    "print(precision, recall, F_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uranium data only\n",
    "## extract and concatenate n experimental raw data files (60 seconds each) into one, then sum up \n",
    "##\n",
    "path = '/home/ndgu-visitor2/project-AI/raw data/uranium/'\n",
    "dirs = os.listdir(path)\n",
    "dir1 = dirs[1]\n",
    "\n",
    "t_config = 60\n",
    "\n",
    "print(dirs)\n",
    "\n",
    "usum = []\n",
    "usumcps = []\n",
    "\n",
    "for dir1 in dirs:\n",
    "    print(dir1)\n",
    "    a = np.loadtxt(path + dir1, delimiter=',', skiprows=1)\n",
    "    a = np.delete(a.T, 0,0)\n",
    "    print(np.shape(a))\n",
    "    print(a[0, 20:100])\n",
    "    print(np.stack(a).shape[0])\n",
    "    b = np.stack(a).shape[0]\n",
    "    c = np.sum(a, axis = 0)\n",
    "    print(c.shape)\n",
    "    print(c[20:100])\n",
    "    d = c/(t_config * b)\n",
    "    np.savetxt(path + '../'+ 'summ/' + dir1 + '_sum.csv', c.T, delimiter = ',')\n",
    "    np.savetxt(path + '../'+ 'summ/cps/' + dir1 + '_sumcps.csv', d.T, delimiter = ',')\n",
    "    \n",
    "    usum.append(c)\n",
    "    usumcps.append(d)\n",
    "    \n",
    "    \n",
    "    print(\"====================\")\n",
    "\n",
    "usum = np.stack(usum)\n",
    "usumcps = np.stack(usumcps)\n",
    "usumcps[0] = usumcps[0]/30   # BG is configured to be 30 minutes interval instead of 1 min like others\n",
    "print(usum.shape, usumcps.shape)\n",
    "\n",
    "np.save(path + 'U_test.npy', usum)\n",
    "np.savetxt(path + 'U_test.csv', usum, delimiter=',')\n",
    "print(usum)\n",
    "\n",
    "delta = load(path + 'U_test.npy')\n",
    "print(delta.shape, delta)\n",
    "\n",
    "np.savetxt(path + 'Sumcps.txt', np.sum(usumcps,axis=1))\n",
    "\n",
    "usumccr = np.sum(usumcps, axis = 1)/np.sum(np.sum(usumcps, axis = 1))\n",
    "\n",
    "print(usumccr.shape)\n",
    "print(usumccr)\n",
    "\n",
    "np.savetxt(path + 'U_YtestCCR.txt', usumccr)\n",
    "\n",
    "print(usumcps[5:100])\n",
    "print(np.sum(usumcps, axis = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_U = np.loadtxt(\"y_test_U235.txt\", encoding = 'utf-8')\n",
    "print(y_test_U.shape)\n",
    "print(y_test_U)\n",
    "\n",
    "delta = load(path+'U_test.npy')\n",
    "dell = delta[1:,Startsize:Datasize] \n",
    "print(dell.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "dell = dell.reshape(dell.shape[0], dell.shape[1], 1)\n",
    "\n",
    "x_test_U = np.row_stack((x_test, dell))\n",
    "print(x_test_U.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = load(path + 'U_test.npy')\n",
    "dell = delta[1:,Startsize:Datasize] \n",
    "dell = dell.reshape(dell.shape[0], dell.shape[1], 1)\n",
    "x_test_U = np.row_stack((x_test, dell))\n",
    "\n",
    "result_y = VGG19model.predict(x_test_U)\n",
    "print(result_y.shape)\n",
    "print(result_y[0,:])\n",
    "\n",
    "BG = result_y[:, 6] + result_y[:, 7] + result_y[:, 8] + result_y[:, 9] # 238, Th, Ra, K\n",
    "BG = BG.reshape(BG.shape[0], 1)\n",
    "\n",
    "res_y = np.hstack((result_y[:, :6], BG))\n",
    "print(BG.shape)\n",
    "print(res_y.shape)\n",
    "\n",
    "names = np.array([\"Co60\", \"Cs137\", \"Na22\", \"Ba133\", \"Eu152\", \"U235\", \"BG\"])\n",
    "\n",
    "\n",
    "left = np.arange(res_y.shape[1])\n",
    "width = 0.4\n",
    "\n",
    "for i in range(res_y.shape[0]):\n",
    "    plt.figure(figsize=(24, 20))\n",
    "    plt.bar(left, res_y[i], width=width, align='center')\n",
    "    plt.bar(left+width, y_test_U[i], width=width, align='center')\n",
    "    plt.xticks(left + width/2, names)\n",
    "    plt.savefig(\"June30-U-100epoch-7bits-Compton-cut60keV-{:03}.png\".format(i))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "np.savetxt(\"result_y_U.csv\",result_y,delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "RI = res_y.T\n",
    "RI_exp = y_test.T\n",
    "TP = []\n",
    "FN = []\n",
    "FP = []\n",
    "\n",
    "for i in range(len(RI)-1):\n",
    "    RI_detected = np.where(RI[i,:]>RI[6,:], 1, 0)\n",
    "    RI_EXP = np.where(RI_exp[i,:]>RI_exp[6,:], 1, 0)\n",
    "    RI_EXP_TP = np.where(RI_EXP == 1, 1, -1)\n",
    "    RI_TP = np.where(RI_detected == RI_EXP_TP, 1, 0)\n",
    "    TP.append(np.sum(RI_TP))\n",
    "    FN.append(np.sum(np.where(RI_EXP>RI_detected, 1,0)))\n",
    "    FP.append(np.sum(np.where(RI_detected>RI_EXP, 1,0)))\n",
    "\n",
    "Tp = np.sum(np.stack(TP))\n",
    "Fn = np.sum(np.stack(FN))\n",
    "Fp = np.sum(np.stack(FP))\n",
    "\n",
    "print(Tp, Fn, Fp)\n",
    "\n",
    "precision = Tp/(Tp+Fp)\n",
    "recall = Tp/(Tp+Fn)\n",
    "F_score = 100*2*precision*recall/(precision + recall)\n",
    "\n",
    "print(precision, recall, F_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################################\n",
    "## Ending of code\n",
    "## Below is just testing area\n",
    "#########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuclides_n = 7\n",
    "xdata = data_x\n",
    "ydata = Y_train_acc\n",
    "#ydata = Y_train_acc_no_U235\n",
    "\n",
    "print(xdata.shape, ydata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VGG19 model定義\n",
    "Ks.clear_session()\n",
    "\n",
    "np.random.seed(10)\n",
    "\n",
    "VGG19model = keras.models.Sequential()\n",
    "\n",
    "VGG19model.add(layers.Conv1D(64, 3, activation = 'relu', padding='same',\n",
    "                       input_shape = (Datasize,1)))\n",
    "VGG19model.add(layers.Conv1D(64, 3, padding='same', activation = 'relu'))\n",
    "VGG19model.add(layers.MaxPooling1D(2))\n",
    "\n",
    "VGG19model.add(layers.Conv1D(128, 3, padding='same', activation = 'relu'))\n",
    "VGG19model.add(layers.Conv1D(128, 3, padding='same', activation = 'relu'))\n",
    "VGG19model.add(layers.MaxPooling1D(2))\n",
    "\n",
    "VGG19model.add(layers.Conv1D(256, 3, padding='same', activation = 'relu'))\n",
    "VGG19model.add(layers.Conv1D(256, 3, padding='same', activation = 'relu'))\n",
    "VGG19model.add(layers.Conv1D(256, 3, padding='same', activation = 'relu'))\n",
    "VGG19model.add(layers.Conv1D(256, 3, padding='same', activation = 'relu'))\n",
    "VGG19model.add(layers.MaxPooling1D(2))\n",
    "VGG19model.add(layers.Conv1D(512, 3, padding='same', activation = 'relu'))\n",
    "VGG19model.add(layers.Conv1D(512, 3, padding='same', activation = 'relu'))\n",
    "VGG19model.add(layers.Conv1D(512, 3, padding='same', activation = 'relu'))\n",
    "VGG19model.add(layers.Conv1D(512, 3, padding='same', activation = 'relu'))\n",
    "VGG19model.add(layers.MaxPooling1D(2))\n",
    "VGG19model.add(layers.Conv1D(512, 3, padding='same', activation = 'relu'))\n",
    "VGG19model.add(layers.Conv1D(512, 3, padding='same', activation = 'relu'))\n",
    "VGG19model.add(layers.Conv1D(512, 3, padding='same', activation = 'relu'))\n",
    "VGG19model.add(layers.Conv1D(512, 3, padding='same', activation = 'relu'))\n",
    "VGG19model.add(layers.MaxPooling1D(2))\n",
    "VGG19model.add(layers.Flatten())\n",
    "#model.add(layers.Dense(64, activation='relu'))\n",
    "VGG19model.add(layers.Dense(1024, activation='relu'))\n",
    "VGG19model.add(layers.Dense(1024, activation='relu'))\n",
    "VGG19model.add(layers.Dropout(0.2))\n",
    "VGG19model.add(layers.Dense(nuclides_n, activation='softmax'))\n",
    "\n",
    "#opt= keras.optimizers.Adam(lr=0.0021533133440412807,\n",
    "#                           decay=8.915893662822524e-09,\n",
    "#                           amsgrad=True)\n",
    "opt = keras.optimizers.Adam()\n",
    "\n",
    "VGG19model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "VGG19model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG19 学習\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "nuclides_n = 6\n",
    "run = 5\n",
    "val_split = 0.1\n",
    "batch_size = 1024\n",
    "ydata = Y_train_acc   ### Y_train_acc_no_U235\n",
    "\n",
    "VGGhistory = VGG19model.fit(xdata, ydata, \n",
    "                    epochs=run,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_split=val_split)\n",
    "#                    callbacks=EarlyStopping(monitor='val_loss',patience=50, verbose=1, min_delta=0,mode=\"auto\"))\n",
    "\n",
    "VGGloss = VGGhistory.history['loss']\n",
    "VGGval_loss = VGGhistory.history['val_loss']\n",
    "\n",
    "epochs= range(len(VGGloss))\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, VGGloss, 'bo', label='training loss')\n",
    "plt.plot(epochs, VGGval_loss, 'b', label='validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "score, acc = VGG19model.evaluate(x_test_U, y_test_U,\n",
    "                            batch_size=batch_size)  ### In case of Y_train_acc_no_U235: (x_test, y_test, ...) \n",
    "print('Test score:', score)\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
